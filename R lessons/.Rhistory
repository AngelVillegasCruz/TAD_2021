textstat_simil(presDfm, c("2009-Obama", "2013-Obama"), margin = "documents", method = "cosine")
summary(presDfm)
summary(corpus(data_char_ukimmig2010, notes = "Created as a demo."))
presDfm
##analyzing coded tweets--total tweets
library(installr)
library(streamR)
library(devtools)
library(Rcpp)
library(ROAuth)
library(quanteda)
library(smappR)
library(dplyr)
library(lubridate)
library(brms)
library(ggplot2)
library(lazyeval)
library(lubridate)
library(ranger)
library(Matrix)
setwd("C:/Users/kevin/Dropbox/youtube/_Data/")
options(scipen=10000)
load("forKmart_termsVids.RData")
dat<-filter(termsResVid, is.na(Ideology) == FALSE)
length(unique(dat$channel_name))
table(dat$Ideology)
dat$date<-as.Date(dat$publication_date)
dat$months<-( substr(dat$date, 1, 7))
plots<-aggregate(x = dat$termCount, by = list(dat$months, as.factor(dat$Ideology), as.factor(dat$term)), FUN = "sum")
ggplot(plots, aes(y = x, x = Group.1, colour = Group.2)) +
geom_point(size = 3) + stat_smooth(span=.6, se=TRUE)+ theme_bw() + ylab("Sum Likes") + xlab("")
plots_sub<-filter(plots, Group.3 == "subscribe")
ggplot(plots_sub, aes(y = x, x = Group.1, colour = Group.2)) +
geom_point(size = 3) + stat_smooth(span=.6, se=TRUE)+ theme_bw() + ylab("Sum Likes") + xlab("")
ggplot(plots_sub, aes(y = x, x = Group.1, colour = Group.2)) +
geom_point(size = 3) + stat_smooth(span=.6, se=TRUE)+ theme_bw() + ylab("Term Frequency") + xlab("") +
ggtile("Subscribe")
ggplot(plots_sub, aes(y = x, x = Group.1, colour = Group.2)) +
geom_point(size = 3) + stat_smooth(span=.6, se=TRUE)+ theme_bw() + ylab("Term Frequency") + xlab("") +
main("Subscribe")
ggplot(plots_sub, aes(y = x, x = Group.1, colour = Group.2)) +
geom_point(size = 3) + stat_smooth(span=.6, se=TRUE)+ theme_bw() + ylab("Term Frequency") + xlab("") +
title("Subscribe")
ggplot(plots_sub, aes(y = x, x = Group.1, colour = Group.2)) +
geom_point(size = 3) + stat_smooth(span=.6, se=TRUE)+ theme_bw() + ylab("Term Frequency") + xlab("") +
title("Subscribe")
ggplot(plots_sub, aes(y = x, x = Group.1, colour = Group.2)) +
geom_point(size = 3) + stat_smooth(span=.6, se=TRUE)+ theme_bw() + ylab("Term Frequency") + xlab("")
ggplot(plots_sub, aes(y = x, x = Group.1, colour = Group.2)) +
geom_point(size = 3) + stat_smooth(span=.6, se=TRUE)+ theme_bw() + ylab("Term Frequency") + xlab("") +theme(axis.text.x = element_text(angle = 45),
)
dev.off()
ggplot(plots_sub, aes(y = x, x = Group.1, colour = Group.2)) +
geom_point(size = 3) + stat_smooth(span=.6, se=TRUE)+ theme_bw() + ylab("Term Frequency") + xlab("") +theme(axis.text.x = element_text(angle = 45))
ggplot(plots_sub, aes(y = x, x = Group.1, colour = Group.2)) +
geom_point(size = 3) + stat_smooth(span=.6, se=TRUE)+ theme_bw() + ylab("Term Frequency") + xlab("") +
theme(axis.text.x = element_text(angle = 45), title = "Subscriber")
ggplot(plots_sub, aes(y = x, x = Group.1, colour = Group.2)) +
geom_point(size = 3) + stat_smooth(span=.6, se=TRUE)+ theme_bw() + ylab("Term Frequency") + xlab("") +
theme(axis.text.x = element_text(angle = 45), title = element_text("Subscribe") )
ggplot(plots_sub, aes(y = x, x = Group.1, colour = Group.2)) +
geom_point(size = 3) + stat_smooth(span=.6, se=TRUE)+ theme_bw() + ylab("Term Frequency") + xlab("") +
theme(axis.text.x = element_text(angle = 45), title = element_text(x ="Subscribe") )
ggplot(plots_sub, aes(y = x, x = Group.1, colour = Group.2)) +
geom_point(size = 3) + stat_smooth(span=.6, se=TRUE)+ theme_bw() + ylab("Term Frequency") + xlab("") +
theme(axis.text.x = element_text(angle = 45) ) +ggtitle("Subscribe")
plots_sub<-filter(plots, Group.3 == "twitch")
ggplot(plots_sub, aes(y = x, x = Group.1, colour = Group.2)) +
geom_point(size = 3) + stat_smooth(span=.6, se=TRUE)+ theme_bw() + ylab("Term Frequency") + xlab("") +
theme(axis.text.x = element_text(angle = 45) ) +ggtitle("Twitch")
plots_sub<-filter(plots, Group.3 == "discord")
ggplot(plots_sub, aes(y = x, x = Group.1, colour = Group.2)) +
geom_point(size = 3) + stat_smooth(span=.6, se=TRUE)+ theme_bw() + ylab("Term Frequency") + xlab("") +
theme(axis.text.x = element_text(angle = 45) ) +ggtitle("Discord")
plots_sub<-filter(plots, Group.3 == "patreon")
ggplot(plots_sub, aes(y = x, x = Group.1, colour = Group.2)) +
geom_point(size = 3) + stat_smooth(span=.6, se=TRUE)+ theme_bw() + ylab("Term Frequency") + xlab("") +
theme(axis.text.x = element_text(angle = 45) ) +ggtitle("Patreon")
pdf("subscribe.pdf", 7, 5)
ggplot(plots_sub, aes(y = x, x = Group.1, colour = Group.2)) +
geom_point(size = 3) + stat_smooth(span=.6, se=TRUE)+ theme_bw() + ylab("Term Frequency") + xlab("") +
theme(axis.text.x = element_text(angle = 45) ) +ggtitle("Subscribe")
dev.off()
plots_sub<-filter(plots, Group.3 == "twitch")
pdf("twitch.pdf", 7, 5)
ggplot(plots_sub, aes(y = x, x = Group.1, colour = Group.2)) +
geom_point(size = 3) + stat_smooth(span=.6, se=TRUE)+ theme_bw() + ylab("Term Frequency") + xlab("") +
theme(axis.text.x = element_text(angle = 45) ) +ggtitle("Twitch")
dev.off()
plots_sub<-filter(plots, Group.3 == "discord")
pdf("discord.pdf", 7, 5)
ggplot(plots_sub, aes(y = x, x = Group.1, colour = Group.2)) +
geom_point(size = 3) + stat_smooth(span=.6, se=TRUE)+ theme_bw() + ylab("Term Frequency") + xlab("") +
theme(axis.text.x = element_text(angle = 45) ) +ggtitle("Discord")
dev.off()
plots_sub<-filter(plots, Group.3 == "patreon")
pdf("patreon.pdf", 7, 5)
ggplot(plots_sub, aes(y = x, x = Group.1, colour = Group.2)) +
geom_point(size = 3) + stat_smooth(span=.6, se=TRUE)+ theme_bw() + ylab("Term Frequency") + xlab("") +
theme(axis.text.x = element_text(angle = 45) ) +ggtitle("Patreon")
dev.off()
plots_sub<-filter(plots, Group.3 == "subscribe")
pdf("subscribe.pdf", 7, 5)
ggplot(plots_sub, aes(y = x, x = Group.1, colour = Group.2)) +
geom_point(size = 3) + stat_smooth(span=.6, se=TRUE)+ theme_bw() + ylab("Term Frequency") + xlab("") +
theme(axis.text.x = element_text(angle = 45) ) +ggtitle("Subscribe")
dev.off()
plots_sub<-filter(plots, Group.3 == "twitch")
pdf("twitch.pdf", 7, 5)
ggplot(plots_sub, aes(y = x, x = Group.1, colour = Group.2)) +
geom_point(size = 3) + stat_smooth(span=.6, se=TRUE)+ theme_bw() + ylab("Term Frequency") + xlab("") +
theme(axis.text.x = element_text(angle = 45) ) +ggtitle("Twitch")
dev.off()
plots_sub<-filter(plots, Group.3 == "discord")
pdf("discord.pdf", 7, 5)
ggplot(plots_sub, aes(y = x, x = Group.1, colour = Group.2)) +
geom_point(size = 3) + stat_smooth(span=.6, se=TRUE)+ theme_bw() + ylab("Term Frequency") + xlab("") +
theme(axis.text.x = element_text(angle = 45) ) +ggtitle("Discord")
dev.off()
plots_sub<-filter(plots, Group.3 == "patreon")
pdf("patreon.pdf", 7, 5)
ggplot(plots_sub, aes(y = x, x = Group.1, colour = Group.2)) +
geom_point(size = 3) + stat_smooth(span=.6, se=TRUE)+ theme_bw() + ylab("Term Frequency") + xlab("") +
theme(axis.text.x = element_text(angle = 45) ) +ggtitle("Patreon")
dev.off()
load("forKmart.RData")
length(unique(termsResVid$channel_name))
plots<-aggregate(x = dat$termCount, by = list( as.factor(dat$Ideology), as.factor(dat$term)), FUN = "sum")
p4 <- ggplot() + geom_bar(aes(y = stat(x), x = Group.2, fill = Group.1 ), data = plots) +
ylab("Videos Uploaded per Month")+ theme_bw() +
theme(axis.text.x = element_text(angle = 45),
) , name = "")
p4 <- ggplot() + geom_bar(aes(y = stat(x), x = Group.2, fill = Group.1 ), data = plots) +
ylab("Videos Uploaded per Month")+ theme_bw() +
theme(axis.text.x = element_text(angle = 45))
p4
p4 <- ggplot() + geom_bar(aes(y = stat(x), x = Group.2, fill = Group.1 ,position="dodge"), data = plots) +
ylab("Videos Uploaded per Month")+ theme_bw() +
theme(axis.text.x = element_text(angle = 45))
p4
p4 <- ggplot() + geom_bar(aes(y = stat(x), x = Group.2, fill = Group.1 ), data = plots,position="dodge") +
ylab("Videos Uploaded per Month")+ theme_bw() +
theme(axis.text.x = element_text(angle = 45))
p4
p4 <- ggplot() + geom_bar(aes(y = x, x = Group.2, fill = Group.1 ), data = plots,position="dodge") +
ylab("Videos Uploaded per Month")+ theme_bw() +
theme(axis.text.x = element_text(angle = 45))
p4
p4 <- ggplot() + geom_bar(aes(y = x, x = Group.2, fill = Group.1 ), data = plots,position="dodge", stat = "identity") +
ylab("Videos Uploaded per Month")+ theme_bw() +
theme(axis.text.x = element_text(angle = 45))
p4
plots<-filter(plots, Group.2 == "subscribe" | Group.2 == "patreon" | Group.2 == "twitch" | Group.2 =="discord")
p4 <- ggplot() + geom_bar(aes(y = x, x = Group.2, fill = Group.1 ), data = plots,position="dodge", stat = "identity") +
ylab("Videos Uploaded per Month")+ theme_bw() +
theme(axis.text.x = element_text(angle = 45))
p4
p4 <- ggplot() + geom_bar(aes(y = x, x = Group.2, fill = Group.1 ), data = plots,position="dodge", stat = "identity") +
ylab("Videos Uploaded per Month")+ theme_bw() +
theme(axis.text.x = element_text(angle = 45, size = 4))
p4
p4 <- ggplot() + geom_bar(aes(y = x, x = Group.2, fill = Group.1 ), data = plots,position="dodge", stat = "identity") +
ylab("Videos Uploaded per Month")+ theme_bw() +
theme(axis.text.x = element_text(angle = 45, size = 40))
p4
p4 <- ggplot() + geom_bar(aes(y = x, x = Group.2, fill = Group.1 ), data = plots,position="dodge", stat = "identity") +
ylab("Videos Uploaded per Month")+ theme_bw() +
theme(axis.text.x = element_text(angle = 45, size = 20))
p4
p4 <- ggplot() + geom_bar(aes(y = x, x = Group.2, fill = Group.1 ), data = plots,position="dodge", stat = "identity") +
ylab("Videos Uploaded per Month")+ theme_bw() + xlab("") +
theme(axis.text.x = element_text(angle = 45, size = 20))
p4
p4 <- ggplot() + geom_bar(aes(y = x, x = Group.2, fill = Group.1 ), data = plots,position="dodge", stat = "identity") +
ylab("Term Frequency")+ theme_bw() + xlab("") + ggtile("Personality-Driven, Independent Channels Mentioning Alternative Platforms in 2020")
theme(axis.text.x = element_text(angle = 45, size = 20))
p4
p4 <- ggplot() + geom_bar(aes(y = x, x = Group.2, fill = Group.1 ), data = plots,position="dodge", stat = "identity") +
ylab("Term Frequency")+ theme_bw() + xlab("") + ggtile("Personality-Driven, Independent Channels Mentioning Alternative Platforms in 2020")+
theme(axis.text.x = element_text(angle = 45, size = 20))
p4
p4 <- ggplot() + geom_bar(aes(y = x, x = Group.2, fill = Group.1 ), data = plots,position="dodge", stat = "identity") +
ylab("Term Frequency")+ theme_bw() + xlab("") + ggtitle("Personality-Driven, Independent Channels Mentioning Alternative Platforms in 2020")+
theme(axis.text.x = element_text(angle = 45, size = 20))
p4
p4 <- ggplot() + geom_bar(aes(y = x, x = Group.2, fill = Group.1 ), data = plots,position="dodge", stat = "identity") +
ylab("Term Frequency")+ theme_bw() + xlab("") + ggtitle("Personality-Driven, Independent Channels in 2020")+
theme(axis.text.x = element_text(angle = 45, size = 20))
p4
pdf("platform_transcripts.pdf", 7, 5)
p4
dev.off()
?as.factor
plots$Ideology<-factor( plots$Group.1, levels = c ("Left", "Center", "Right"))
plots<-aggregate(x = dat$termCount, by = list( as.factor(dat$Ideology), as.factor(dat$term)), FUN = "sum")
plots$Ideology<-factor( plots$Group.1, levels = c ("Left", "Center", "Right"))
plots<-filter(plots, Group.2 == "subscribe" | Group.2 == "patreon" | Group.2 == "twitch" | Group.2 =="discord")
p4 <- ggplot() + geom_bar(aes(y = x, x = Group.2, fill = Ideology ), data = plots,position="dodge", stat = "identity") +
ylab("Term Frequency")+ theme_bw() + xlab("") + ggtitle("Personality-Driven, Independent Channels in 2020")+
theme(axis.text.x = element_text(angle = 45, size = 20))
p4
pdf("platform_transcripts.pdf", 7, 5)
p4
dev.off()
table(dat$Personality)
persInd<-filter(dat, Personality == "Yes" & Org == "No")
plots<-aggregate(x = persInd$termCount, by = list( as.factor(persInd$Ideology), as.factor(persInd$term)), FUN = "sum")
plots$Ideology<-factor( plots$Group.1, levels = c ("Left", "Center", "Right"))
plots<-filter(plots, Group.2 == "subscribe" | Group.2 == "patreon" | Group.2 == "twitch" | Group.2 =="discord")
p4 <- ggplot() + geom_bar(aes(y = x, x = Group.2, fill = Ideology ), data = plots,position="dodge", stat = "identity") +
ylab("Term Frequency")+ theme_bw() + xlab("") + ggtitle("Personality-Driven, Independent Channels in 2020")+
theme(axis.text.x = element_text(angle = 45, size = 20))
pdf("platform_transcripts_persInd.pdf", 7, 5)
p4
dev.off()
p4
persInd<-filter(dat, Personality == "Yes" & Org == "Yes")
plots<-aggregate(x = persInd$termCount, by = list( as.factor(persInd$Ideology), as.factor(persInd$term)), FUN = "sum")
plots$Ideology<-factor( plots$Group.1, levels = c ("Left", "Center", "Right"))
plots<-filter(plots, Group.2 == "subscribe" | Group.2 == "patreon" | Group.2 == "twitch" | Group.2 =="discord")
p4 <- ggplot() + geom_bar(aes(y = x, x = Group.2, fill = Ideology ), data = plots,position="dodge", stat = "identity") +
ylab("Term Frequency")+ theme_bw() + xlab("") + ggtitle("Personality-Driven, Affiliated Channels in 2020")+
theme(axis.text.x = element_text(angle = 45, size = 20))
p4
pdf("platform_transcripts_persAff.pdf", 7, 5)
p4
dev.off()
rm(list = ls())
setwd("C:/Users/kevin/Documents/GitHub/TAD_2021/R_lessons/")
setwd("C:/Users/kevin/Documents/GitHub/TAD_2021/R lessons/")
library(quanteda)
library(dplyr)
filenames <- list.files(path = "conservative_manifestos", full.names=TRUE)
cons_manifestos <- lapply(filenames, readLines)
filenames <- list.files(path = "conservative_manifestos", full.names=TRUE)
cons_manifestos <- lapply(filenames, readLines)
cons_manifestos <- unlist(lapply(cons_manifestos, function(x) paste(x, collapse = " "))) # because readLines returns a vector with each elements = lines
manifestos_df <- data.frame( text = cons_manifestos)
mytexts <- c("The new law included a capital gains tax, and an inheritance tax.",
"New York City has raised a taxes: an income tax and a sales tax.")
mydict <- c("tax", "income", "capital", "gains", "inheritance")
print(dfm(mytexts, select = mydict))
lgdict <- dictionary(file = "LaverGarry.cat", format = "wordstat",encoding = "utf-8")
lgdict
manifestos_lg <- dfm(manifestos_df$text, dictionary = lgdict)
manifestos_lg <- dfm(manifestos_df, dictionary = lgdict)
manifestos_df <- data.frame( text = as.character(cons_manifestos))
manifestos_df <- data.frame( text = as.character(cons_manifestos))
manifestos_lg <- dfm(manifestos_df, dictionary = lgdict)
manifestos_lg <- dfm(manifestos_df$text, dictionary = lgdict)
manifestos_df <- data.frame( text = as.character(cons_manifestos))
manifestos_df <- data.frame( text = as.character(cons_manifestos), stringsAsFactors = F)
manifestos_lg <- dfm(manifestos_df$text, dictionary = lgdict)
as.matrix(manifestos_lg)[1:5, 1:5]
featnames(manifestos_lg)
plot(     manifestos_lg[,"CULTURE.SPORT"],
xlab="Year", ylab="SPORTS", type="b", pch=19)
plot(year,
inaugural_rid_dfm[,"PRIMARY.ICARIAN_IM.FIRE"] + inaugural_rid_dfm[,"PRIMARY.ICARIAN_IM.ASCEND"] +inaugural_rid_dfm[,"PRIMARY.ICARIAN_IM.DESCENT"] +
inaugural_rid_dfm[,"PRIMARY.ICARIAN_IM.DEPTH"] + inaugural_rid_dfm[,"PRIMARY.ICARIAN_IM.HEIGHT"] + inaugural_rid_dfm[,"PRIMARY.ICARIAN_IM.WATER"],
xlab="Year", ylab="Icarian-ness", type="b", pch=19)
rid_dict <- dictionary(file = "RID.cat", format = "wordstat",encoding = "utf-8")
data("data_corpus_inaugural")
inaugurals_texts <- texts(data_corpus_inaugural)
year <- (data_corpus_inaugural$Year)
pres <- (data_corpus_inaugural$President)
inaugural_rid_dfm <- dfm(data_corpus_inaugural, dictionary = rid_dict)
featnames(inaugural_rid_dfm)
plot(year,
inaugural_rid_dfm[,"PRIMARY.REGR_KNOL.NARCISSISM"],
xlab="Year", ylab="Narcissism", type="b", pch=19)
plot(year,
inaugural_rid_dfm[,"EMOTIONS.POSITIVE_AFFECT"],
xlab="Year", ylab="Narcissism", type="b", pch=19)
plot(year,
inaugural_rid_dfm[,"PRIMARY.ICARIAN_IM.FIRE"] + inaugural_rid_dfm[,"PRIMARY.ICARIAN_IM.ASCEND"] +inaugural_rid_dfm[,"PRIMARY.ICARIAN_IM.DESCENT"] +
inaugural_rid_dfm[,"PRIMARY.ICARIAN_IM.DEPTH"] + inaugural_rid_dfm[,"PRIMARY.ICARIAN_IM.HEIGHT"] + inaugural_rid_dfm[,"PRIMARY.ICARIAN_IM.WATER"],
xlab="Year", ylab="Icarian-ness", type="b", pch=19)
----------------------
# Set up environment                   ---
#----------------------------------------
# clear global environment
rm(list = ls())
setwd("C:/Users/kevin/Documents/GitHub/TAD_2021/R lessons/")
----------------------
# Set up environment                   ---
#----------------------------------------
# clear global environment
rm(list = ls())
setwd("C:/Users/kevin/Documents/GitHub/TAD_2021/R lessons/")
library(quanteda)
library(quanteda.textmodels)
install.packages('quanteda.textmodels')
news_data <- readRDS("news_data.rds")
news_samp <- filter(news_data, category %in% c("CRIME", "SPORTS"))
news_samp1 <- select(news_samp, headline, category)
news_samp2<-setNames(object = news_samp1, nm = c("text", "class"))
dim(news_samp2)
head(news_samp2$text[news_samp2$class == "CRIME"])
head(news_samp2$text[news_samp2$class == "SPORTS"])
news_samp2$text <- gsub(pattern = "'", "", news_samp2$text)  # replace apostrophes
head(news_samp2$text[news_samp2$class == "SPORTS"])
prop.table(table(news_samp2$class))
set.seed(1984L)
prop_train <- 0.8
ids <- 1:nrow(news_samp2)
ids_train <- sample(ids, ceiling(prop_train*length(ids)), replace = FALSE)
ids_test <- ids[-ids_train]
train_set <- news_samp2[ids_train,]
test_set <- news_samp2[ids_test,]
train_dfm <- dfm(train_set$text, stem = TRUE, remove_punct = TRUE, remove = stopwords("english"))
test_dfm <- dfm(test_set$text, stem = TRUE, remove_punct = TRUE, remove = stopwords("english"))
as.matrix(train_dfm)[1:5,1:5]
test_dfm <- dfm_match(test_dfm, features = featnames(train_dfm))
nb_model <- textmodel_nb(train_dfm, train_set$class, smooth = 0, prior = "uniform")
nb_model <- quanteda::textmodel_nb(train_dfm, train_set$class, smooth = 0, prior = "uniform")
nb_model <- quanteda::textmodel_NB(train_dfm, train_set$class, smooth = 0, prior = "uniform")
nb_model <- textmodel_NB(train_dfm, train_set$class, smooth = 0, prior = "uniform")
nb_model <- textmodel_nb(train_dfm, train_set$class, smooth = 0, prior = "uniform")
install.packages('quanteda.textmodels')
install.packages('quanteda.textmodels')
library(quanteda.textmodels)
library(readtext)
library(dplyr)
nb_model <- textmodel_nb(train_dfm, train_set$class, smooth = 0, prior = "uniform")
predicted_class <- predict(nb_model, newdata = test_dfm)
baseline_acc <- max(prop.table(table(test_set$class)))
cmat <- table(test_set$class, predicted_class)
nb_acc <- sum(diag(cmat))/sum(cmat) # accuracy = (TP + TN) / (TP + FP + TN + FN)
nb_recall <- cmat[2,2]/sum(cmat[2,]) # recall = TP / (TP + FN)
nb_precision <- cmat[2,2]/sum(cmat[,2]) # precision = TP / (TP + FP)
nb_f1 <- 2*(nb_recall*nb_precision)/(nb_recall + nb_precision)
cat(
"Baseline Accuracy: ", baseline_acc, "\n",
"Accuracy:",  nb_acc, "\n",
"Recall:",  nb_recall, "\n",
"Precision:",  nb_precision, "\n",
"F1-score:", nb_f1
)
nb_model_sm <- textmodel_nb(train_dfm, train_set$class, smooth = 1, prior = "uniform")
predicted_class_sm <- predict(nb_model_sm, newdata = test_dfm)
cmat_sm <- table(test_set$class, predicted_class_sm)
nb_acc_sm <- sum(diag(cmat_sm))/sum(cmat_sm) # accuracy = (TP + TN) / (TP + FP + TN + FN)
nb_recall_sm <- cmat_sm[2,2]/sum(cmat_sm[2,]) # recall = TP / (TP + FN)
nb_precision_sm <- cmat_sm[2,2]/sum(cmat_sm[,2]) # precision = TP / (TP + FP)
nb_f1_sm <- 2*(nb_recall_sm*nb_precision_sm)/(nb_recall_sm + nb_precision_sm)
cat(
"Baseline Accuracy: ", baseline_acc, "\n",
"Accuracy:",  nb_acc_sm, "\n",
"Recall:",  nb_recall_sm, "\n",
"Precision:",  nb_precision_sm, "\n",
"F1-score:", nb_f1_sm
)
posterior <- data.frame(feature = rownames(t(nb_model_sm$param)),
post_CRIME = t(nb_model_sm$param)[,1],
post_SPORTS = t(nb_model_sm$param)[,2])
head(arrange(posterior, -post_SPORTS))
head(arrange(posterior, -post_CRIME))
plot(nb_model$param[1,], nb_model_sm$param[1,], xlim = c(0,0.02), ylim = c(0,0.02), xlab="No Smooth", ylab="Smooth") + abline(a = 0, b = 1, col = "red")
rm(list = ls())
rm(list = ls())
file.choose()
setwd("C:/Users/kevin/Documents/GitHub/TAD_2021/R lessons/")
library(quanteda)
library(dplyr)
manifestos_df <- data.frame( text = cons_manifestos)
filenames <- list.files(path = "conservative_manifestos", full.names=TRUE)
cons_manifestos <- lapply(filenames, readLines)
cons_manifestos <- unlist(lapply(cons_manifestos, function(x) paste(x, collapse = " "))) # because readLines returns a vector with each elements = lines
cons_manifestos[1]
manifestos_df <- data.frame( text = cons_manifestos)
mytexts <- c("The new law included a capital gains tax, and an inheritance tax.",
"New York City has raised a taxes: an income tax and a sales tax.")
mydict <- c("tax", "income", "capital", "gains", "inheritance")
print(dfm(mytexts, select = mydict))
print(dfm(mytexts))
lgdict <- dictionary(file = "LaverGarry.cat", format = "wordstat",encoding = "utf-8")
lgdict
manifestos_lg <- dfm(manifestos_df$text, dictionary = lgdict)
manifestos_df$text
manifestos_df <- data.frame( text = cons_manifestos, stringsAsFactors = F)
manifestos_lg <- dfm(manifestos_df$text, dictionary = lgdict)
as.matrix(manifestos_lg)[1:5, 1:5]
manifestos_lg
manifestos_lg[,"CULTURE.SPORT"]
plot(     manifestos_lg[,"CULTURE.SPORT"],
xlab="Year", ylab="SPORTS", type="b", pch=19)
plot(
manifestos_lg[,"VALUES.CONSERVATIVE"],
xlab="Year", ylab="Conservative values", type="b", pch=19)
plot(
manifestos_lg[,"VALUES.CONSERVATIVE"],
xlab="Year", ylab="Conservative values", type="a", pch=19)
plot(
manifestos_lg[,"VALUES.CONSERVATIVE"],
xlab="Year", ylab="Conservative values", type="c", pch=19)
plot(
manifestos_lg[,"VALUES.CONSERVATIVE"],
xlab="Year", ylab="Conservative values", type="b", pch=19)
plot(
manifestos_lg[,"VALUES.CONSERVATIVE"],
xlab="Year", ylab="Conservative values", type="b", pch=6)
plot(
manifestos_lg[,"VALUES.CONSERVATIVE"],
xlab="Year", ylab="Conservative values", type="b", pch=7)
plot(
manifestos_lg[,"INSTITUTIONS.CONSERVATIVE"] - manifestos_lg[,"INSTITUTIONS.RADICAL"],
xlab="Year", ylab="Net Conservative Institutions", type="b", pch=19)
rid_dict <- dictionary(file = "RID.cat", format = "wordstat",encoding = "utf-8")
data("data_corpus_inaugural")
inaugurals_texts <- texts(data_corpus_inaugural)
year <- (data_corpus_inaugural$Year)
pres <- (data_corpus_inaugural$President)
inaugural_rid_dfm <- dfm(data_corpus_inaugural, dictionary = rid_dict)
featnames(inaugural_rid_dfm)
plot(year,
inaugural_rid_dfm[,"PRIMARY.REGR_KNOL.NARCISSISM"],
xlab="Year", ylab="Narcissism", type="b", pch=19)
plot(year,
inaugural_rid_dfm[,"EMOTIONS.POSITIVE_AFFECT"],
xlab="Year", ylab="Positivity", type="b", pch=19)
plot(year,
inaugural_rid_dfm[,"PRIMARY.ICARIAN_IM.FIRE"] + inaugural_rid_dfm[,"PRIMARY.ICARIAN_IM.ASCEND"] +inaugural_rid_dfm[,"PRIMARY.ICARIAN_IM.DESCENT"] +
inaugural_rid_dfm[,"PRIMARY.ICARIAN_IM.DEPTH"] + inaugural_rid_dfm[,"PRIMARY.ICARIAN_IM.HEIGHT"] + inaugural_rid_dfm[,"PRIMARY.ICARIAN_IM.WATER"],
xlab="Year", ylab="Icarian-ness", type="b", pch=19)
plot(year,
inaugural_rid_dfm[,"EMOTIONS.POSITIVE_AFFECT"],
xlab="Year", ylab="Positivity", type="b", pch=19)
plot(year,
inaugural_rid_dfm[,"PRIMARY.REGR_KNOL.NARCISSISM"],
xlab="Year", ylab="Narcissism", type="b", pch=19)
----------------------
# Set up environment                   ---
#----------------------------------------
# clear global environment
rm(list = ls())
setwd("C:/Users/kevin/Documents/GitHub/TAD_2021/R lessons/")
library(quanteda)
install.packages('quanteda.textmodels')
install.packages("quanteda.textmodels")
library(quanteda.textmodels)
library(readtext)
library(dplyr)
news_data <- readRDS("news_data.rds")
news_samp <- filter(news_data, category %in% c("CRIME", "SPORTS"))
news_samp1 <- select(news_samp, headline, category)
news_samp2<-setNames(object = news_samp1, nm = c("text", "class"))
dim(news_samp2)
head(news_samp2$text[news_samp2$class == "CRIME"])
head(news_samp2$text[news_samp2$class == "SPORTS"])
news_samp2$text <- gsub(pattern = "'", "", news_samp2$text)  # replace apostrophes
head(news_samp2$text[news_samp2$class == "SPORTS"])
prop.table(table(news_samp2$class))
table(news_samp2$class)
set.seed(1984L)
prop_train <- 0.8
ids <- 1:nrow(news_samp2)
length(ids)
prop_train*length(ids)
ceiling(prop_train*length(ids))
ids_train <- sample(ids, ceiling(prop_train*length(ids)), replace = FALSE)
ids_test <- ids[-ids_train]
train_set <- news_samp2[ids_train,]
test_set <- news_samp2[ids_test,]
train_dfm <- dfm(train_set$text, stem = TRUE, remove_punct = TRUE, remove = stopwords("english"))
test_dfm <- dfm(test_set$text, stem = TRUE, remove_punct = TRUE, remove = stopwords("english"))
library(quanteda)
train_dfm <- dfm(train_set$text, stem = TRUE, remove_punct = TRUE, remove = stopwords("english"))
test_dfm <- dfm(test_set$text, stem = TRUE, remove_punct = TRUE, remove = stopwords("english"))
as.matrix(train_dfm)[1:5,1:5]
test_dfm <- dfm_match(test_dfm, features = featnames(train_dfm))
nb_model <- textmodel_nb(train_dfm, train_set$class, smooth = 0, prior = "uniform")
predicted_class <- predict(nb_model, newdata = test_dfm)
baseline_acc <- max(prop.table(table(test_set$class)))
baseline_acc
cmat <- table(test_set$class, predicted_class)
cmat
nb_acc <- sum(diag(cmat))/sum(cmat) # accuracy = (TP + TN) / (TP + FP + TN + FN)
nb_recall <- cmat[2,2]/sum(cmat[2,]) # recall = TP / (TP + FN)
nb_precision <- cmat[2,2]/sum(cmat[,2]) # precision = TP / (TP + FP)
nb_f1 <- 2*(nb_recall*nb_precision)/(nb_recall + nb_precision)
cat(
"Baseline Accuracy: ", baseline_acc, "\n",
"Accuracy:",  nb_acc, "\n",
"Recall:",  nb_recall, "\n",
"Precision:",  nb_precision, "\n",
"F1-score:", nb_f1
)
nb_model_sm <- textmodel_nb(train_dfm, train_set$class, smooth = 1, prior = "uniform")
predicted_class_sm <- predict(nb_model_sm, newdata = test_dfm)
cmat_sm <- table(test_set$class, predicted_class_sm)
nb_acc_sm <- sum(diag(cmat_sm))/sum(cmat_sm) # accuracy = (TP + TN) / (TP + FP + TN + FN)
nb_recall_sm <- cmat_sm[2,2]/sum(cmat_sm[2,]) # recall = TP / (TP + FN)
nb_precision_sm <- cmat_sm[2,2]/sum(cmat_sm[,2]) # precision = TP / (TP + FP)
nb_f1_sm <- 2*(nb_recall_sm*nb_precision_sm)/(nb_recall_sm + nb_precision_sm)
cat(
"Baseline Accuracy: ", baseline_acc, "\n",
"Accuracy:",  nb_acc_sm, "\n",
"Recall:",  nb_recall_sm, "\n",
"Precision:",  nb_precision_sm, "\n",
"F1-score:", nb_f1_sm
)
posterior <- data.frame(feature = rownames(t(nb_model_sm$param)),
post_CRIME = t(nb_model_sm$param)[,1],
post_SPORTS = t(nb_model_sm$param)[,2])
head(arrange(posterior, -post_SPORTS))
head(arrange(posterior, -post_CRIME))
plot(nb_model$param[1,], nb_model_sm$param[1,], xlim = c(0,0.02), ylim = c(0,0.02), xlab="No Smooth", ylab="Smooth") + abline(a = 0, b = 1, col = "red")
setwd("~/GitHub/TAD_2021/R lessons")
install.packages('quanteda.textmodels')
library(quanteda)
?textmodel_nb
